{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNUwSu9QULNN"
      },
      "outputs": [],
      "source": [
        "!pip install patool\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjatXXPUUPOK"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjffJxQvUPRE"
      },
      "outputs": [],
      "source": [
        "import patoolib\n",
        "patoolib.extract_archive(\"/content/drive/MyDrive/dataset/bicep_dumbbell2.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUNEkZaO7Dlr"
      },
      "outputs": [],
      "source": [
        "# Download the model from TF Hub.\n",
        "import tensorflow_hub as hub\n",
        "model = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
        "movenet = model.signatures['serving_default']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kj8290qg-k5h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "# import pafy\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import tensorflow as tf\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# from moviepy.editor import *\n",
        "# %matplotlib inline\n",
        " \n",
        "from sklearn.model_selection import train_test_split\n",
        " \n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "L0tsfUny7LzN"
      },
      "outputs": [],
      "source": [
        "pose_image_size = 192\n",
        "visibility_threshold = .10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DSjjU10D0dP"
      },
      "outputs": [],
      "source": [
        "# Specify the height and width to which each video frame will be resized in our dataset.\n",
        "# IMAGE_WIDTH = int(1280/4)\n",
        "# IMAGE_HEIGHT = int(720/4)\n",
        "\n",
        "IMAGE_WIDTH = 200\n",
        "IMAGE_HEIGHT = 200\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(IMAGE_WIDTH,IMAGE_HEIGHT)\n",
        "\n",
        "# Specify the number of frames of a video that will be fed to the model as one sequence.\n",
        "SEQUENCE_LENGTH = 22"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZjH016x6JZCJ"
      },
      "outputs": [],
      "source": [
        "image_paths = glob.glob(\"/content/bicep_dumbbell2/bicep_dumbbell2/*.avi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Bgo75zXU4dg"
      },
      "outputs": [],
      "source": [
        "len(image_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9YXB0bnJD0f9"
      },
      "outputs": [],
      "source": [
        "def frames_extraction(video_path):\n",
        "\n",
        "    # Declare a list to store video frames.\n",
        "    frames_list = []\n",
        "    tem_frames = []\n",
        "    labels_list = []\n",
        "    video_reader = cv2.VideoCapture(video_path)\n",
        "    label = int(video_path.split('/')[4].split('_')[1])\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    count = 0 \n",
        "    while(cap.isOpened()):\n",
        "        ret, frame = cap.read()\n",
        "        count+=1\n",
        "        try:\n",
        "          frame = cv2.resize(frame, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
        "          frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "          #------Start Cropping images-------------\n",
        "          image = tf.expand_dims(frame, axis=0)\n",
        "          image = tf.cast(tf.image.resize_with_pad(image, pose_image_size, pose_image_size), dtype=tf.int32)\n",
        "          # Run model inference.\n",
        "          outputs = movenet(image)\n",
        "          keypoints = outputs['output_0']\n",
        "          keypoints = keypoints[0][0]\n",
        "          # get one hand\n",
        "          right_hand = np.array(np.array(keypoints[10])*IMAGE_WIDTH , dtype=np.int16)\n",
        "          # Cropping image\n",
        "          try:\n",
        "            frame = tf.image.crop_to_bounding_box( np.array(frame), right_hand[0]-40, right_hand[1]-40, 80, 80 )\n",
        "            # corp_image_arr.append(crop_image)\n",
        "          except:\n",
        "            frame = tf.zeros([80, 80], tf.int32)\n",
        "          # print(np.array(frame).shape)\n",
        "          #-------------------------------\n",
        "          normalized_frame = frame / 255\n",
        "          tem_frames.append(normalized_frame)\n",
        "          \n",
        "          if len(tem_frames) == SEQUENCE_LENGTH: \n",
        "            frames_list.append(tem_frames)\n",
        "            tem_frames = []\n",
        "            labels_list.append(int(label))\n",
        "        except:\n",
        "          print(f\"last frame of {str(video_path.split('/')[2])} => {count}\")\n",
        "          cap.release()\n",
        "          cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    # Return the frames list.\n",
        "    return np.array(frames_list) , np.array(labels_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYTL1tSAKv6C"
      },
      "outputs": [],
      "source": [
        "# images_list = np.zeros((1,SEQUENCE_LENGTH ,IMAGE_HEIGHT , IMAGE_WIDTH , 3))\n",
        "images_list = np.zeros((1,SEQUENCE_LENGTH ,80 , 80 , 3))\n",
        "labels_list = []\n",
        "for idx ,  image_path in enumerate(image_paths):\n",
        "  print(idx)\n",
        "  try:\n",
        "    images , label = frames_extraction(image_path)\n",
        "    # print(np.array(images[]).shape)\n",
        "    images_list = np.concatenate(( images_list, images ), axis=0)\n",
        "    labels_list = np.concatenate((labels_list , label ) , axis = 0)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "# remove first element which is used for creatation\n",
        "images_list = images_list[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeznmL6FjWtE"
      },
      "outputs": [],
      "source": [
        "labels_list = [int(x) for x in labels_list]\n",
        "type(labels_list[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMg4thN_j2xD"
      },
      "outputs": [],
      "source": [
        "labels_list[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "US4RRUukMskE"
      },
      "outputs": [],
      "source": [
        "np.array(images_list).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YB35EFSM8V6"
      },
      "outputs": [],
      "source": [
        "np.array(labels_list).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYdeqo0sD0sH"
      },
      "outputs": [],
      "source": [
        "np.unique(labels_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9swlIdpnD0xc"
      },
      "outputs": [],
      "source": [
        "random_group = np.random.randint(images_list.shape[0])\n",
        "\n",
        "print(labels_list[random_group])\n",
        "\n",
        "fig,a =  plt.subplots(3,3 , figsize=(10, 10))\n",
        "a[0][0].imshow(images_list[random_group][0])\n",
        "a[0][1].imshow(images_list[random_group][1])\n",
        "a[0][2].imshow(images_list[random_group][2])\n",
        "a[1][0].imshow(images_list[random_group][3])\n",
        "a[1][1].imshow(images_list[random_group][4])\n",
        "a[1][2].imshow(images_list[random_group][5])\n",
        "a[2][0].imshow(images_list[random_group][6])\n",
        "a[2][1].imshow(images_list[random_group][7])\n",
        "a[2][2].imshow(images_list[random_group][8])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4qblcE2EKU5"
      },
      "outputs": [],
      "source": [
        "features_train, features_test, labels_train, labels_test = train_test_split(np.array(images_list), np.array(labels_list), test_size = 0.8, shuffle = True, random_state = 52)\n",
        "\n",
        "# del(images_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YygNlJiEKYC"
      },
      "outputs": [],
      "source": [
        "def create_LRCN_model():\n",
        "    '''\n",
        "    This function will construct the required LRCN model.\n",
        "    Returns:\n",
        "        model: It is the required constructed LRCN model.\n",
        "    '''\n",
        "\n",
        "\n",
        "\n",
        "    # We will use a Sequential model for model construction.\n",
        "    model = Sequential()\n",
        "    \n",
        "\n",
        "    # Define the Model Architecture.\n",
        "    ########################################################################################################################\n",
        "    \n",
        "    model.add(TimeDistributed(Conv2D(16, (3, 3), padding='same',activation = 'relu'),\n",
        "                              input_shape = (SEQUENCE_LENGTH, 80, 80, 3)))\n",
        "    \n",
        "    model.add(TimeDistributed(MaxPooling2D((2, 2)))) \n",
        "    model.add(TimeDistributed(Dropout(0.25)))\n",
        "    \n",
        "    model.add(TimeDistributed(Conv2D(32, (3, 3), padding='same',activation = 'relu')))\n",
        "    model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "    model.add(TimeDistributed(Dropout(0.25)))\n",
        "    \n",
        "    model.add(TimeDistributed(Conv2D(32, (3, 3), padding='same',activation = 'relu')))\n",
        "    model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "    model.add(TimeDistributed(Dropout(0.25)))\n",
        "\n",
        "    # model.add(TimeDistributed(Conv2D(32, (3, 3), padding='same',activation = 'relu')))\n",
        "    # model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "    # model.add(TimeDistributed(Dropout(0.25)))\n",
        "\n",
        "\n",
        "    # model.add(TimeDistributed(Conv2D(64, (3, 3), padding='same',activation = 'relu')))\n",
        "    # model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "    # model.add(TimeDistributed(Dropout(0.25)))\n",
        "    \n",
        "    model.add(TimeDistributed(Conv2D(64, (3, 3), padding='same',activation = 'relu')))\n",
        "    model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "    model.add(TimeDistributed(Dropout(0.25)))\n",
        "                                      \n",
        "    model.add(TimeDistributed(Flatten()))\n",
        "                                      \n",
        "    model.add(LSTM(300,  activation=\"tanh\" , return_sequences=True))\n",
        "    # model.add(LSTM(16,  activation=\"tanh\" , return_sequences=True))\n",
        "    model.add(LSTM(300,  activation=\"tanh\" , return_sequences=True))\n",
        "    # model.add(LSTM(32,  activation=\"tanh\" , return_sequences=True))\n",
        "    model.add(LSTM(400,  activation=\"tanh\" , return_sequences=True))\n",
        "    model.add(LSTM(400,  activation=\"tanh\" ))\n",
        "\n",
        "\n",
        "\n",
        "    # model.add(tf.keras.layers.Bidirectional( LSTM(200,  activation=\"tanh\" , return_sequences=True)) )\n",
        "    # model.add(tf.keras.layers.Bidirectional( LSTM(300, activation=\"tanh\")) )\n",
        "\n",
        "\n",
        "\n",
        "    model.add(Dense( 500, activation = 'tanh') )\n",
        "    # model.add(Dense( 300, activation = 'tanh') )\n",
        "    # model.add(Dense( 300, activation = 'tanh') )\n",
        "\n",
        "\n",
        "                               \n",
        "    model.add(Dense(len(np.unique(labels_list)), activation = 'softmax'))\n",
        "\n",
        "    ########################################################################################################################\n",
        "\n",
        "    # Display the models summary.\n",
        "    # model.summary()\n",
        "    \n",
        "    # Return the constructed LRCN model.\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIrhFm71EKbG"
      },
      "outputs": [],
      "source": [
        "# Construct the required LRCN model.\n",
        "LRCN_model = create_LRCN_model()\n",
        "\n",
        "#\n",
        "# Create an Instance of Early Stopping Callback.\n",
        "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 45, mode = 'min', restore_best_weights = True)\n",
        "\n",
        "\n",
        "# Compile the model and specify loss function, optimizer and metrics to the model.\n",
        "LRCN_model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(), \n",
        "                       optimizer = tf.keras.optimizers.Adam(learning_rate=0.001), \n",
        "                       metrics = [\"accuracy\"])\n",
        "# Start training the model.\n",
        "LRCN_model_training_history = LRCN_model.fit(x = features_train, y = labels_train, epochs = 200, batch_size = 4 , shuffle = True, validation_split = 0.2, callbacks = [early_stopping_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGwiLwKiw0F1"
      },
      "outputs": [],
      "source": [
        "LRCN_model.evaluate(features_test , labels_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTanvzWUEKde"
      },
      "outputs": [],
      "source": [
        "for x in range(10):\n",
        "  selected_test_video = x\n",
        "  result = LRCN_model.predict(np.expand_dims(features_test[selected_test_video], axis = 0), np.array(labels_test[selected_test_video]))\n",
        "  print(np.argmax(result))\n",
        "  print(f\"Real label {labels_test[selected_test_video] }\")\n",
        "  print(\"==========\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b40wqVYziZCB"
      },
      "outputs": [],
      "source": [
        "# LRCN_model.save('LRCN_model_22f_v_1.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wElZcUPX6btv"
      },
      "source": [
        "# **Different Model that can be used**\n",
        "But it is slow and has similer accuracey as prevois model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qoqsv6XXun2K"
      },
      "outputs": [],
      "source": [
        "# def create_convlstm_model():\n",
        "\n",
        "#     model = Sequential()\n",
        "\n",
        "#     model.add(ConvLSTM2D(filters = 8, kernel_size = (3, 3), activation = 'tanh',data_format = \"channels_last\",\n",
        "#                          recurrent_dropout=0.2, return_sequences=True, input_shape = (SEQUENCE_LENGTH,\n",
        "#                                                                                       80, 80, 3)))\n",
        "    \n",
        "#     model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n",
        "#     model.add(TimeDistributed(Dropout(0.2)))\n",
        "    \n",
        "#     model.add(ConvLSTM2D(filters = 16, kernel_size = (3, 3), activation = 'tanh', data_format = \"channels_last\",\n",
        "#                          recurrent_dropout=0.2, return_sequences=True))\n",
        "    \n",
        "#     model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n",
        "#     model.add(TimeDistributed(Dropout(0.2)))\n",
        "    \n",
        "#     model.add(ConvLSTM2D(filters = 28, kernel_size = (3, 3), activation = 'tanh', data_format = \"channels_last\",\n",
        "#                          recurrent_dropout=0.2, return_sequences=True))\n",
        "    \n",
        "#     model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n",
        "#     model.add(TimeDistributed(Dropout(0.2)))\n",
        "    \n",
        "#     model.add(ConvLSTM2D(filters = 16, kernel_size = (3, 3), activation = 'tanh', data_format = \"channels_last\",\n",
        "#                          recurrent_dropout=0.2, return_sequences=True))\n",
        "    \n",
        "#     model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n",
        "#     #model.add(TimeDistributed(Dropout(0.2)))\n",
        "    \n",
        "#     model.add(Flatten()) \n",
        "\n",
        "#     model.add(Dense( 50, activation = 'tanh'))\n",
        "#     model.add(Dropout(0.3))\n",
        "#     model.add(Dense( 50, activation = 'tanh'))\n",
        "#     model.add(Dropout(0.3))    \n",
        "#     model.add(Dense( 50, activation = 'tanh'))\n",
        "#     model.add(Dropout(0.3))\n",
        "    \n",
        "#     model.add(Dense(len(np.unique(labels_list)), activation = \"softmax\"))\n",
        "\n",
        "#     return model\n",
        "\n",
        "\n",
        "# # Construct the required convlstm model.\n",
        "# convlstm_model = create_convlstm_model()\n",
        "\n",
        "\n",
        "# # Create an Instance of Early Stopping Callback\n",
        "# early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 25, mode = 'min', restore_best_weights = True)\n",
        "\n",
        "# # Compile the model and specify loss function, optimizer and metrics values to the model\n",
        "# convlstm_model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(), \n",
        "#                        optimizer = 'Adam', \n",
        "#                        metrics = [\"accuracy\"])\n",
        "\n",
        "# # Start training the model.\n",
        "# convlstm_model_training_history = convlstm_model.fit(x = features_train, y = labels_train, epochs = 50, batch_size = 4,shuffle = True, validation_split = 0.2, callbacks = [early_stopping_callback])\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}